{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a11ef81c-5453-4e33-ba19-d900a2572552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Masterthesis_Persons_Statistics\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def statistics_persons(link, driver, FounderOrEmployee=\"E\"):\n",
    "    #open company link for extracting persons statistics\n",
    "    driver.get(link)\n",
    "    \n",
    "    time.sleep(random.uniform(2, 5))\n",
    "    #clicking \"Persons\" button\n",
    "    try:\n",
    "        link = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.LINK_TEXT, \"People\"))  # Example XPATH\"\n",
    "        )\n",
    "        \n",
    "        # Click the button\n",
    "        link.click()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "    #clicking \"show more\" button\n",
    "    try:\n",
    "        # Wait until the button is clickable using XPath\n",
    "        button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'org-people__show-more-button')]\"))\n",
    "        )\n",
    "        \n",
    "        # Click the button\n",
    "        button.click()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "    #Filter for founders if necessary\n",
    "    if FounderOrEmployee==\"F\":\n",
    "        try:\n",
    "            searchinput = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID,\"people-search-keywords\"))\n",
    "            )\n",
    "            searchinput.clear()#making sure that there is not text inside because the sended key will be appended\n",
    "            searchinput.send_keys(\"Founder\")\n",
    "            searchinput.send_keys(Keys.ENTER)\n",
    "        except Exception as e:\n",
    "            print(\"error\")\n",
    "    \n",
    "        time.sleep(2)\n",
    "    \n",
    "    #df_1, df_2\n",
    "    #Extract the first df of a company Persons statistics\n",
    "    def firstdf(div_text):\n",
    "        extracted_text = div_text \n",
    "        # Step 1: Split the text into lines and filter out empty lines\n",
    "        lines = [line.strip() for line in extracted_text.split('\\n') if line.strip()]\n",
    "        \n",
    "        # Step 2: Find the index of the first occurrence of \"Hinzufügen\" and capture the word before it\n",
    "        hinzufuegen_count = 0\n",
    "        before_hinzufuegen = None\n",
    "        end_index = None\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            if \"Add\" in line:\n",
    "                hinzufuegen_count += 1\n",
    "                if hinzufuegen_count == 1:  # Capture the word before the first occurrence\n",
    "                    before_hinzufuegen = lines[i - 1]\n",
    "                if hinzufuegen_count == 2:  # Find the end index for extraction\n",
    "                    end_index = i\n",
    "                    break\n",
    "        \n",
    "        # Step 3: Extract lines up to the second \"Hinzufügen\"\n",
    "        if end_index is not None:\n",
    "            relevant_lines = lines[:end_index - 1]  # Exclude the second \"Hinzufügen\"\n",
    "        else:\n",
    "            relevant_lines = lines  # If not found, take all lines\n",
    "        \n",
    "        # Step 4: Remove unwanted words (\"ausschalten\") and format the data\n",
    "        cleaned_lines = [re.sub(r'\\bausschalten\\b', '', line).strip() for line in relevant_lines]\n",
    "        cleaned_lines = [line for line in cleaned_lines if line]  # Remove empty lines\n",
    "        \n",
    "        # Initialize lists to hold amounts and locations\n",
    "        amounts = []\n",
    "        locations = []\n",
    "        \n",
    "        # Step 5: Extract amounts and locations from the cleaned lines\n",
    "        for line in cleaned_lines:\n",
    "            match = re.match(r'(\\d+)\\s*(.*)', line)\n",
    "            if match:\n",
    "                amounts.append(int(match.group(1)))  # Convert to integer\n",
    "                locations.append(match.group(2).strip())  # Get the location\n",
    "        \n",
    "        # Step 6: Create a DataFrame with the desired column name\n",
    "        df_1 = pd.DataFrame({\n",
    "            'Amount': amounts,\n",
    "            before_hinzufuegen: locations  # Use the word before \"Hinzufügen\" as the column name\n",
    "        })\n",
    "        \n",
    "        return df_1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Extract the second df of a company Persons statistics\n",
    "    def seconddf(div_text):\n",
    "        extracted_text = div_text \n",
    "        # Step 1: Split the text into lines and filter out empty lines\n",
    "        lines = [line.strip() for line in extracted_text.split('\\n') if line.strip()]\n",
    "    \n",
    "        \n",
    "        # Step 2: Find the index of the second occurrence of \"Hinzufügen\"\n",
    "        hinzufuegen_count = 0\n",
    "        start_index = None\n",
    "        before_hinzufuegen = None\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            if \"Add\" in line:\n",
    "                hinzufuegen_count += 1\n",
    "                if hinzufuegen_count == 2:  # Find the second occurrence\n",
    "                    start_index = i - 1  # Start one word before \"Hinzufügen\"\n",
    "                    before_hinzufuegen = lines[i - 1]  # Store the word before \"Hinzufügen\"\n",
    "                    break\n",
    "        \n",
    "        # Step 3: Extract lines starting from one before the second \"Hinzufügen\"\n",
    "    \n",
    "        if start_index is not None:\n",
    "            relevant_lines = lines[start_index:]  # Get lines from the start index to the end\n",
    "        else:\n",
    "            relevant_lines = []  # If not found, take no lines\n",
    "        \n",
    "        # Step 4: Remove unwanted words (\"ausschalten\") and format the data\n",
    "        cleaned_lines = [re.sub(r'\\bausschalten\\b', '', line).strip() for line in relevant_lines]\n",
    "        cleaned_lines = [line for line in cleaned_lines if line]  # Remove empty lines\n",
    "        \n",
    "        # Initialize lists to hold amounts and locations for the second DataFrame\n",
    "        amounts_2 = []\n",
    "        locations_2 = []\n",
    "        \n",
    "        # Step 5: Extract amounts and locations from the cleaned lines\n",
    "    \n",
    "        for line in cleaned_lines:\n",
    "            match = re.match(r'(\\d+)\\s*(.*)', line)\n",
    "            if match:\n",
    "                amounts_2.append(int(match.group(1)))  # Convert to integer\n",
    "                locations_2.append(match.group(2).strip())  # Get the location\n",
    "        \n",
    "        # Step 6: Create the second DataFrame\n",
    "        df_2 = pd.DataFrame({\n",
    "            'Amount': amounts_2,\n",
    "            before_hinzufuegen: locations_2  # Use the word before \"Hinzufügen\" as the column name\n",
    "        })\n",
    "        \n",
    "        # Step 7: Drop rows where the second column has no values\n",
    "        df_2 = df_2[df_2.iloc[:, 1] != '']  # Keep only rows where the second column is not empty\n",
    "        \n",
    "        return df_2\n",
    "    \n",
    "    \n",
    "    # Wait for the <div> to be present and extract the text for df_1, df_2\n",
    "    try:\n",
    "        div_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'artdeco-carousel__content'))  # Replace with your div's XPath or other selector\n",
    "        )\n",
    "        \n",
    "        # Extract the text\n",
    "        div_text = div_element.text\n",
    "        #df=tabolizer(div_text)\n",
    "    \n",
    "        #print(div_text)\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "    \n",
    "    \n",
    "    df_1 = firstdf(div_text)\n",
    "    df_2 = seconddf(div_text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #df_3 to df_6\n",
    "    #Extract from the third df of a company Persons statistics\n",
    "    def dffrom3(div_text,df_2):\n",
    "        extracted_text = div_text\n",
    "        # Step 1: Split the text into lines and filter out empty lines\n",
    "        lines = [line.strip() for line in extracted_text.split('\\n') if line.strip()]\n",
    "        \n",
    "        # Step 2: Find the first occurrence of a number\n",
    "        first_number_index = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if re.match(r'^\\d+', line):  # Check if the line starts with a number\n",
    "                first_number_index = i\n",
    "                break\n",
    "        \n",
    "    \n",
    "        # Step 3: Extract relevant lines starting from the first number\n",
    "        if first_number_index is not None:\n",
    "            relevant_lines = lines[first_number_index:]  # Get lines from the first number to the end\n",
    "        else:\n",
    "            relevant_lines = []  # If no numbers found, take no lines\n",
    "        \n",
    "        # Step 4: Remove unwanted words (\"ausschalten\") and format the data\n",
    "        cleaned_lines = [re.sub(r'\\bausschalten\\b', '', line).strip() for line in relevant_lines]\n",
    "        cleaned_lines = [line for line in cleaned_lines if line]  # Remove empty lines\n",
    "        \n",
    "        # Initialize lists to hold amounts and fields for the new DataFrame\n",
    "        amounts = []\n",
    "        fields = []\n",
    "    \n",
    "        \n",
    "        # Step 5: Extract amounts and fields from the cleaned lines\n",
    "        for line in cleaned_lines:\n",
    "            match = re.match(r'(\\d+)\\s*(.*)', line)  # Match the number and the text\n",
    "            if match:\n",
    "                amounts.append(int(match.group(1)))  # Convert to integer\n",
    "                fields.append(match.group(2).strip())  # Get the field\n",
    "        \n",
    "        # Step 6: Create the new DataFrame\n",
    "        df_new = pd.DataFrame({\n",
    "            'Amount': amounts,\n",
    "            'Field': fields  # Naming the second column \"Field\"\n",
    "        })\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        # Step 7: Subtract df_2 from df_new using column index\n",
    "        df_3 = df_new[~df_new.iloc[:, 1].isin(df_2.iloc[:, 1])]  # Using index 1 for 'Field'\n",
    "        \n",
    "        # Step 8: Change the name of the right column based on the value in df_3\n",
    "        if not df_3.empty:  # Check if df_3 is not empty\n",
    "            number_to_match = df_3.iloc[0, 0]  # Get the number from the first row, first column (Amount)\n",
    "            \n",
    "            # Find the line above the first occurrence of the number in the original lines\n",
    "            column_name = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if re.match(rf'^{number_to_match}\\s', line):  # Match the line with the number\n",
    "                    if i > 0:  # Ensure there's a line above it\n",
    "                        column_name = lines[i - 1]\n",
    "                    break\n",
    "            \n",
    "            # Rename the second column in df_3\n",
    "            if column_name:\n",
    "                df_3.columns = ['Amount', column_name]\n",
    "        \n",
    "        return df_3\n",
    "    \n",
    "    \n",
    "    # Loop through the function above to extract df_3 until df_6\n",
    "    try:\n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        # Wait until the button is clickable using XPath\n",
    "        button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Next']\"))\n",
    "        )\n",
    "        \n",
    "        # Click the button\n",
    "        button.click()\n",
    "    except Exception as e:\n",
    "            print(\"error\")\n",
    "    \n",
    "    df_3 = pd.DataFrame()\n",
    "    df_4 = pd.DataFrame()\n",
    "    df_5 = pd.DataFrame()\n",
    "    df_6 = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    list = [df_3,df_4,df_5,df_6]\n",
    "    memory = df_2\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for df in enumerate(list):\n",
    "        try:\n",
    "            time.sleep(random.uniform(2, 5))\n",
    "            # Wait until the button is clickable using XPath\n",
    "            button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Next']\"))\n",
    "            )\n",
    "            \n",
    "            # Click the button\n",
    "            button.click()\n",
    "            \n",
    "    \n",
    "            div_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'artdeco-carousel__content'))  # Replace with your div's XPath or other selector\n",
    "            )\n",
    "            \n",
    "    \n",
    "            # Extract the text\n",
    "            div_text = div_element.text\n",
    "            #df=tabolizer(div_text)\n",
    "        \n",
    "            #print(div_text)\n",
    "        except Exception as e:\n",
    "            print(\"error\")\n",
    "    \n",
    "    \n",
    "        \n",
    "        df = dffrom3(div_text,memory)\n",
    "        memory = df\n",
    "        dfs.append(df)\n",
    "        #print(df)\n",
    "    \n",
    "    \n",
    "    df_3,df_4,df_5,df_6 = dfs\n",
    "    return df_1, df_2, df_3, df_4, df_5, df_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812ebd8b-c957-4750-b8bd-bd862f458d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in Dictonary of Dataframes\n",
    "def persons_statistics(internal_id, Company_LinkedIN_Link, dataframes_Persons_Statistics, driver):\n",
    "    try:\n",
    "        # Company name and URL\n",
    "        #company_name = \"52_hertz\"\n",
    "        \n",
    "        # Get data for male and female statistics\n",
    "        df_1, df_2, df_3, df_4, df_5, df_6 = statistics_persons(Company_LinkedIN_Link, driver, \"E\")\n",
    "        #Fdf_1, Fdf_2, Fdf_3, Fdf_4, Fdf_5, Fdf_6 = statistics_persons(f\"https://www.linkedin.com/company/{company_name.replace('_', '-')}\", driver, \"F\")\n",
    "        \n",
    "        # Store DataFrames in the dictionary using the new format\n",
    "        dataframes_Persons_Statistics[f\"df_1_{internal_id}\"] = df_1\n",
    "        dataframes_Persons_Statistics[f\"df_2_{internal_id}\"] = df_2\n",
    "        dataframes_Persons_Statistics[f\"df_3_{internal_id}\"] = df_3\n",
    "        dataframes_Persons_Statistics[f\"df_4_{internal_id}\"] = df_4\n",
    "        dataframes_Persons_Statistics[f\"df_5_{internal_id}\"] = df_5\n",
    "        dataframes_Persons_Statistics[f\"df_6_{internal_id}\"] = df_6\n",
    "        \"\"\"\n",
    "        dataframes_Persons_Statistics[f\"Fdf_1_{company_name}\"] = Fdf_1\n",
    "        dataframes_Persons_Statistics[f\"Fdf_2_{company_name}\"] = Fdf_2\n",
    "        dataframes_Persons_Statistics[f\"Fdf_3_{company_name}\"] = Fdf_3\n",
    "        dataframes_Persons_Statistics[f\"Fdf_4_{company_name}\"] = Fdf_4\n",
    "        dataframes_Persons_Statistics[f\"Fdf_5_{company_name}\"] = Fdf_5\n",
    "        dataframes_Persons_Statistics[f\"Fdf_6_{company_name}\"] = Fdf_6\n",
    "        \"\"\"\n",
    "        # Example of how to access the dynamically created DataFrames from the dictionary\n",
    "        #print(dataframes_Persons_Statistics[f\"df_1_52_hertz\"][f\"df_1_{company_name}\"])  # Accessing the employee DataFrame\n",
    "        #print(dataframes_Persons_Statistics[f\"df_1_52_hertz\"][f\"Fdf_1_{company_name}\"])  # Accessing the founder DataFrame\n",
    "        #dataframes_Persons_Statistics[f\"df_1_52_hertz\"][f\"df_1_52_hertz\"]\n",
    "    except:\n",
    "        pass\n",
    "    return dataframes_Persons_Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f38de-450e-4283-b5c9-f99bc3f2c6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
